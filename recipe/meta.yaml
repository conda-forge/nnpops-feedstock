{% set name = "nnpops" %}
{% set version = "0.6" %}
# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
{% set torch_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

{% if cuda_compiler_version in (None, "None", True, False) %}
{% set cuda_major = 0 %}
{% else %}
{% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0] | int %}
{% endif %}

package:
  name: {{ name }}
  version: {{ version }}

source:
  url: https://github.com/openmm/NNPOps/archive/refs/tags/v{{ version }}.tar.gz
  sha256: d7854a3506720aa7536ce64ea9b8d621cad5c024ba4979f2156afcc88b2117a3
  patches:
      - patches/fix-osx-lib-loading.patch  # [osx]
      - patches/cpp17.patch
build:
  skip: true  # [win]
  number: 13
  rpaths:
    - lib/
    - {{ SP_DIR }}/torch/lib
  missing_dso_whitelist:
    - '*/libcuda.*'  # [linux64]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - {{ compiler('cxx') }}
    - {{ stdlib("c") }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != 'None']
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version not in (undefined, 'None')]
    {% if cuda_major >= 12 %}
    - cuda-cudart-dev
    # No cuda-driver-dev in windows
    - cuda-driver-dev  # [linux]
    - libcufft-dev
    - libcurand-dev
    - libcublas-dev
    - cuda-nvrtc-dev
    - cuda-nvtx-dev
    - cuda-profiler-api
    - cuda-nvrtc-dev
    - libcusparse-dev
    - libcusolver-dev
    {% endif %}
    - make
    - cmake
  host:
    - python
    - pytorch =*={{ torch_proc_type }}*
  run:
    - python
    - torchani
    - cuda-version  # [cuda_compiler_version not in (undefined, 'None')]
  run_constrained:
    # additional run constraint to the one from the (version-only) run_export;
    # constraining the CPU builds to CPU pytorch isn't 100% necessary, but cleaner
    - pytorch =*={{ torch_proc_type }}*

test:
  requires:
    - mdtraj
    - pytest
    - numpy
  imports:
    - NNPOps
    - NNPOps.OptimizedTorchANI
  commands: |
    cd ${CONDA_PREFIX}/share/{{ name }}/tests
    ls -al
    set +e
    summary=""
    exitcode=0
    for f in Test*.py; do
      if [[ $f == *Cuda* || $f == *OpenCL* ]]; then
        continue
      fi
      echo "Running $f..."
      pytest -v ./${f}
      thisexitcode=$?
      summary+="\n${f}: "
      if [[ $thisexitcode == 0 ]]; then summary+="OK"; else summary+="FAILED"; fi
      ((exitcode+=$thisexitcode))
    done
    echo "-------"
    echo "Summary"
    echo "-------"
    echo -e "${summary}"
    exit $exitcode

about:
  home: https://github.com/openmm/NNPOps
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: High performance implementations of operations used in Neural Network Potentials

extra:
  recipe-maintainers:
    - raimis
    - mikemhenry
    - h-vetinari
    - RaulPPelaez
