{% set version = "0.4" %}
# see github.com/conda-forge/conda-forge.github.io/issues/1059 for naming discussion
{% set torch_proc_type = "cuda" if cuda_compiler_version != "None" else "cpu" %}

package:
  name: nnpops
  version: {{ version }}

source:
  url: https://github.com/openmm/NNPOps/archive/refs/tags/v{{ version }}.tar.gz
  sha256: 81857fbb2ce3092243987a5cf2db4cb52352ab2f086d266ddf59edfebf0e92f5

build:
  skip: true  # [not linux]
  # as of pytorch 1.13, conda-forge only builds for CUDA 11.2+, see
  # https://github.com/conda-forge/conda-forge-pinning-feedstock/issues/3491
  skip: true  # [cuda_compiler_version not in ("None", "11.2")]
  number: 0
  rpaths:
    - lib/
    - {{ SP_DIR }}/torch/lib
  missing_dso_whitelist:
    - '*/libcuda.*'  # [linux64]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == "None"]

requirements:
  build:
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != 'None']
    - sysroot_linux-64  2.17  # [linux64]
    - make
    - cmake
  host:
    - python
    - pytorch
    - pytorch =*={{ torch_proc_type }}*
    - torchani
    - mdtraj
    - pytest
  run:
    - python
    - torchani
  run_constrained:
    # additional run constraint to the one from the (version-only) run_export;
    # constraining the CPU builds to CPU pytorch isn't 100% necessary, but cleaner
    - pytorch =*={{ torch_proc_type }}*

test:
  imports:
    - NNPOps
    - NNPOps.OptimizedTorchANI

about:
  home: https://github.com/openmm/NNPOps
  license: MIT
  license_family: MIT
  license_file: LICENSE
  summary: High performance implementations of operations used in Neural Network Potentials

extra:
  recipe-maintainers:
    - mikemhenry
    - h-vetinari
